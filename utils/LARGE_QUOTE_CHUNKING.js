// ========================================
// ëŒ€ìš©ëŸ‰ ê²¬ì ì„œ ì²­í‚¹ ë° ë¶„í•  ì²˜ë¦¬ ì‹œìŠ¤í…œ
// LARGE_QUOTE_CHUNKING.js
// ========================================

import { toast } from 'react-toastify';

// ========================================
// 1. ì²­í‚¹ ì„¤ì • ë° ìƒìˆ˜
// ========================================

const CHUNK_CONFIG = {
  // JSON í¬ê¸° ì œí•œ (PostgreSQL JSONB ì œí•œ ê³ ë ¤)
  MAX_JSON_SIZE: 64 * 1024, // 64KB (ì•ˆì „ ë§ˆì§„)
  MAX_ITEMS_PER_CHUNK: 50,    // ì²­í¬ë‹¹ ìµœëŒ€ ì•„ì´í…œ ìˆ˜
  MAX_DETAILS_PER_CHUNK: 100, // ì²­í¬ë‹¹ ìµœëŒ€ ìƒì„¸ í•­ëª© ìˆ˜
  
  // ì²­í‚¹ ì „ëµ
  CHUNK_STRATEGY: {
    BY_SIZE: 'size',
    BY_COUNT: 'count', 
    BY_COMPLEXITY: 'complexity',
    ADAPTIVE: 'adaptive'
  },
  
  // ì„±ëŠ¥ ì„ê³„ê°’
  PERFORMANCE_THRESHOLDS: {
    PROCESSING_TIME: 5000, // 5ì´ˆ
    MEMORY_USAGE: 50 * 1024 * 1024, // 50MB
    NETWORK_TIMEOUT: 30000 // 30ì´ˆ
  }
};

// ========================================
// 2. ê²¬ì ì„œ í¬ê¸° ë¶„ì„ê¸°
// ========================================

class QuoteAnalyzer {
  static analyzeQuoteSize(quoteData) {
    const analysis = {
      jsonSize: this.getJSONSize(quoteData),
      totalGroups: 0,
      totalItems: 0,
      totalDetails: 0,
      complexity: 0,
      estimatedProcessingTime: 0,
      needsChunking: false,
      chunkingStrategy: null
    };

    // êµ¬ì¡° ë¶„ì„
    if (quoteData.groups && Array.isArray(quoteData.groups)) {
      analysis.totalGroups = quoteData.groups.length;
      
      quoteData.groups.forEach(group => {
        if (group.items && Array.isArray(group.items)) {
          analysis.totalItems += group.items.length;
          
          group.items.forEach(item => {
            if (item.details && Array.isArray(item.details)) {
              analysis.totalDetails += item.details.length;
            }
          });
        }
      });
    }

    // ë³µì¡ë„ ê³„ì‚°
    analysis.complexity = this.calculateComplexity(analysis);
    
    // ì²˜ë¦¬ ì‹œê°„ ì˜ˆì¸¡ (ê²½í—˜ì  ê³µì‹)
    analysis.estimatedProcessingTime = this.estimateProcessingTime(analysis);
    
    // ì²­í‚¹ í•„ìš”ì„± íŒë‹¨
    analysis.needsChunking = this.needsChunking(analysis);
    
    // ì²­í‚¹ ì „ëµ ê²°ì •
    if (analysis.needsChunking) {
      analysis.chunkingStrategy = this.determineStrategy(analysis);
    }

    return analysis;
  }

  static getJSONSize(data) {
    try {
      return new Blob([JSON.stringify(data)]).size;
    } catch (error) {
      // í´ë°±: ë¬¸ìì—´ ê¸¸ì´ ê¸°ë°˜ ì¶”ì •
      return JSON.stringify(data).length * 2; // UTF-16 ê°€ì •
    }
  }

  static calculateComplexity(analysis) {
    // ê°€ì¤‘ì¹˜ ê¸°ë°˜ ë³µì¡ë„ ê³„ì‚°
    return (
      analysis.totalGroups * 1 +
      analysis.totalItems * 2 +
      analysis.totalDetails * 3 +
      (analysis.jsonSize / 1024) * 0.1
    );
  }

  static estimateProcessingTime(analysis) {
    // ê²½í—˜ì  ê³µì‹ (ms)
    return Math.max(
      100, // ìµœì†Œ 100ms
      analysis.complexity * 10 +
      analysis.jsonSize / 100
    );
  }

  static needsChunking(analysis) {
    return (
      analysis.jsonSize > CHUNK_CONFIG.MAX_JSON_SIZE ||
      analysis.totalDetails > CHUNK_CONFIG.MAX_DETAILS_PER_CHUNK ||
      analysis.estimatedProcessingTime > CHUNK_CONFIG.PERFORMANCE_THRESHOLDS.PROCESSING_TIME
    );
  }

  static determineStrategy(analysis) {
    if (analysis.jsonSize > CHUNK_CONFIG.MAX_JSON_SIZE) {
      return CHUNK_CONFIG.CHUNK_STRATEGY.BY_SIZE;
    } else if (analysis.totalDetails > CHUNK_CONFIG.MAX_DETAILS_PER_CHUNK) {
      return CHUNK_CONFIG.CHUNK_STRATEGY.BY_COUNT;
    } else {
      return CHUNK_CONFIG.CHUNK_STRATEGY.ADAPTIVE;
    }
  }
}

// ========================================
// 3. ì²­í‚¹ ì—”ì§„
// ========================================

class ChunkingEngine {
  static chunkQuote(quoteData, strategy = CHUNK_CONFIG.CHUNK_STRATEGY.ADAPTIVE) {
    const analysis = QuoteAnalyzer.analyzeQuoteSize(quoteData);
    
    if (!analysis.needsChunking) {
      return {
        chunks: [{ ...quoteData, chunkIndex: 0, totalChunks: 1 }],
        metadata: {
          originalSize: analysis.jsonSize,
          totalChunks: 1,
          strategy: 'none',
          analysis
        }
      };
    }

    console.log('ğŸ”„ ëŒ€ìš©ëŸ‰ ê²¬ì ì„œ ì²­í‚¹ ì‹œì‘:', analysis);
    
    let chunks = [];
    const actualStrategy = strategy === CHUNK_CONFIG.CHUNK_STRATEGY.ADAPTIVE ? 
      analysis.chunkingStrategy : strategy;

    switch (actualStrategy) {
      case CHUNK_CONFIG.CHUNK_STRATEGY.BY_SIZE:
        chunks = this.chunkBySize(quoteData);
        break;
      case CHUNK_CONFIG.CHUNK_STRATEGY.BY_COUNT:
        chunks = this.chunkByCount(quoteData);
        break;
      case CHUNK_CONFIG.CHUNK_STRATEGY.BY_COMPLEXITY:
        chunks = this.chunkByComplexity(quoteData);
        break;
      default:
        chunks = this.adaptiveChunking(quoteData);
    }

    return {
      chunks,
      metadata: {
        originalSize: analysis.jsonSize,
        totalChunks: chunks.length,
        strategy: actualStrategy,
        analysis
      }
    };
  }

  // í¬ê¸° ê¸°ë°˜ ì²­í‚¹
  static chunkBySize(quoteData) {
    const chunks = [];
    const targetChunkSize = CHUNK_CONFIG.MAX_JSON_SIZE * 0.8; // 20% ë§ˆì§„
    
    let currentChunk = {
      ...this.createBaseChunk(quoteData),
      groups: []
    };

    for (const group of quoteData.groups || []) {
      const groupCopy = { ...group, items: [] };
      
      for (const item of group.items || []) {
        const itemCopy = { ...item, details: [] };
        
        for (const detail of item.details || []) {
          itemCopy.details.push(detail);
          
          // í˜„ì¬ ì²­í¬ í¬ê¸° í™•ì¸
          const testChunk = {
            ...currentChunk,
            groups: [...currentChunk.groups, { ...groupCopy, items: [itemCopy] }]
          };
          
          if (QuoteAnalyzer.getJSONSize(testChunk) > targetChunkSize) {
            // í˜„ì¬ ì²­í¬ ì™„ë£Œ ë° ìƒˆ ì²­í¬ ì‹œì‘
            if (currentChunk.groups.length > 0) {
              chunks.push(currentChunk);
            }
            currentChunk = {
              ...this.createBaseChunk(quoteData),
              groups: [{ ...groupCopy, items: [itemCopy] }]
            };
          }
        }
        
        // ì•„ì´í…œì„ í˜„ì¬ ì²­í¬ì— ì¶”ê°€
        const existingGroup = currentChunk.groups.find(g => g.id === group.id);
        if (existingGroup) {
          existingGroup.items.push(itemCopy);
        } else {
          currentChunk.groups.push({ ...groupCopy, items: [itemCopy] });
        }
      }
    }

    // ë§ˆì§€ë§‰ ì²­í¬ ì¶”ê°€
    if (currentChunk.groups.length > 0) {
      chunks.push(currentChunk);
    }

    return this.finalizeChunks(chunks);
  }

  // ê°œìˆ˜ ê¸°ë°˜ ì²­í‚¹
  static chunkByCount(quoteData) {
    const chunks = [];
    const maxDetailsPerChunk = CHUNK_CONFIG.MAX_DETAILS_PER_CHUNK;
    
    let currentChunk = {
      ...this.createBaseChunk(quoteData),
      groups: []
    };
    let currentDetailCount = 0;

    for (const group of quoteData.groups || []) {
      const groupCopy = { ...group, items: [] };
      
      for (const item of group.items || []) {
        const itemCopy = { ...item, details: [] };
        
        for (const detail of item.details || []) {
          if (currentDetailCount >= maxDetailsPerChunk) {
            // í˜„ì¬ ì²­í¬ ì™„ë£Œ
            if (currentChunk.groups.length > 0) {
              chunks.push(currentChunk);
            }
            currentChunk = {
              ...this.createBaseChunk(quoteData),
              groups: []
            };
            currentDetailCount = 0;
          }
          
          itemCopy.details.push(detail);
          currentDetailCount++;
        }
        
        // ì•„ì´í…œì„ í˜„ì¬ ì²­í¬ì— ì¶”ê°€
        const existingGroup = currentChunk.groups.find(g => g.id === group.id);
        if (existingGroup) {
          existingGroup.items.push(itemCopy);
        } else {
          currentChunk.groups.push({ ...groupCopy, items: [itemCopy] });
        }
      }
    }

    // ë§ˆì§€ë§‰ ì²­í¬ ì¶”ê°€
    if (currentChunk.groups.length > 0) {
      chunks.push(currentChunk);
    }

    return this.finalizeChunks(chunks);
  }

  // ë³µì¡ë„ ê¸°ë°˜ ì²­í‚¹ (ìµœì‹  ì•Œê³ ë¦¬ì¦˜)
  static chunkByComplexity(quoteData) {
    const chunks = [];
    const maxComplexityPerChunk = 1000; // ë³µì¡ë„ ì„ê³„ê°’
    
    let currentChunk = {
      ...this.createBaseChunk(quoteData),
      groups: []
    };
    let currentComplexity = 0;

    for (const group of quoteData.groups || []) {
      const groupComplexity = this.calculateGroupComplexity(group);
      
      if (currentComplexity + groupComplexity > maxComplexityPerChunk && currentChunk.groups.length > 0) {
        chunks.push(currentChunk);
        currentChunk = {
          ...this.createBaseChunk(quoteData),
          groups: []
        };
        currentComplexity = 0;
      }
      
      currentChunk.groups.push(group);
      currentComplexity += groupComplexity;
    }

    // ë§ˆì§€ë§‰ ì²­í¬ ì¶”ê°€
    if (currentChunk.groups.length > 0) {
      chunks.push(currentChunk);
    }

    return this.finalizeChunks(chunks);
  }

  // ì ì‘í˜• ì²­í‚¹
  static adaptiveChunking(quoteData) {
    const analysis = QuoteAnalyzer.analyzeQuoteSize(quoteData);
    
    // í¬ê¸°ê°€ ì£¼ ë¬¸ì œì¸ ê²½ìš°
    if (analysis.jsonSize > CHUNK_CONFIG.MAX_JSON_SIZE * 0.8) {
      return this.chunkBySize(quoteData);
    }
    // ê°œìˆ˜ê°€ ì£¼ ë¬¸ì œì¸ ê²½ìš°
    else if (analysis.totalDetails > CHUNK_CONFIG.MAX_DETAILS_PER_CHUNK) {
      return this.chunkByCount(quoteData);
    }
    // ë³µì¡ë„ê°€ ì£¼ ë¬¸ì œì¸ ê²½ìš°
    else {
      return this.chunkByComplexity(quoteData);
    }
  }

  // í—¬í¼ ë©”ì„œë“œë“¤
  static createBaseChunk(originalQuote) {
    const { groups, ...baseData } = originalQuote;
    return baseData;
  }

  static calculateGroupComplexity(group) {
    let complexity = 1; // ê·¸ë£¹ ìì²´
    
    if (group.items) {
      complexity += group.items.length * 2; // ì•„ì´í…œë“¤
      
      group.items.forEach(item => {
        if (item.details) {
          complexity += item.details.length * 3; // ì„¸ë¶€ì‚¬í•­ë“¤
        }
      });
    }
    
    return complexity;
  }

  static finalizeChunks(chunks) {
    return chunks.map((chunk, index) => ({
      ...chunk,
      chunkIndex: index,
      totalChunks: chunks.length
    }));
  }
}

// ========================================
// 4. ë³‘ë ¬ ì²˜ë¦¬ ê´€ë¦¬ì
// ========================================

class ParallelProcessingManager {
  constructor() {
    this.activeProcesses = new Map();
    this.maxConcurrency = 3; // ë™ì‹œ ì²˜ë¦¬ ê°œìˆ˜ ì œí•œ
    this.processQueue = [];
  }

  async processChunksInParallel(chunks, processor, options = {}) {
    const {
      maxRetries = 3,
      retryDelay = 1000,
      progressCallback = null,
      errorCallback = null
    } = options;

    const results = new Array(chunks.length);
    const errors = new Array(chunks.length);
    let completed = 0;
    let failed = 0;

    const processChunk = async (chunk, index) => {
      const processId = `chunk_${index}_${Date.now()}`;
      this.activeProcesses.set(processId, {
        chunkIndex: index,
        startTime: Date.now(),
        retries: 0
      });

      let lastError = null;
      
      for (let retry = 0; retry <= maxRetries; retry++) {
        try {
          const result = await this.executeWithTimeout(
            () => processor(chunk, index),
            CHUNK_CONFIG.PERFORMANCE_THRESHOLDS.NETWORK_TIMEOUT
          );
          
          results[index] = result;
          completed++;
          
          if (progressCallback) {
            progressCallback({
              completed: completed + failed,
              total: chunks.length,
              chunkIndex: index,
              success: true
            });
          }
          
          this.activeProcesses.delete(processId);
          return result;
          
        } catch (error) {
          lastError = error;
          console.warn(`ì²­í¬ ${index} ì²˜ë¦¬ ì‹¤íŒ¨ (ì‹œë„ ${retry + 1}/${maxRetries + 1}):`, error);
          
          if (retry < maxRetries) {
            await this.delay(retryDelay * Math.pow(2, retry)); // ì§€ìˆ˜ ë°±ì˜¤í”„
          }
        }
      }
      
      // ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨
      errors[index] = lastError;
      failed++;
      
      if (errorCallback) {
        errorCallback({
          chunkIndex: index,
          error: lastError,
          chunk
        });
      }
      
      if (progressCallback) {
        progressCallback({
          completed: completed + failed,
          total: chunks.length,
          chunkIndex: index,
          success: false,
          error: lastError
        });
      }
      
      this.activeProcesses.delete(processId);
      throw lastError;
    };

    // ì„¸ë§ˆí¬ì–´ë¥¼ ì‚¬ìš©í•œ ë™ì‹œì„± ì œì–´
    const semaphore = new Semaphore(this.maxConcurrency);
    
    const promises = chunks.map(async (chunk, index) => {
      await semaphore.acquire();
      try {
        return await processChunk(chunk, index);
      } finally {
        semaphore.release();
      }
    });

    const settled = await Promise.allSettled(promises);
    
    // ê²°ê³¼ ì •ë¦¬
    const successfulResults = [];
    const failedChunks = [];
    
    settled.forEach((result, index) => {
      if (result.status === 'fulfilled') {
        successfulResults.push({
          index,
          chunk: chunks[index],
          result: result.value
        });
      } else {
        failedChunks.push({
          index,
          chunk: chunks[index],
          error: result.reason
        });
      }
    });

    return {
      results: successfulResults,
      errors: failedChunks,
      statistics: {
        total: chunks.length,
        successful: successfulResults.length,
        failed: failedChunks.length,
        successRate: (successfulResults.length / chunks.length) * 100
      }
    };
  }

  async executeWithTimeout(fn, timeout) {
    return new Promise((resolve, reject) => {
      const timeoutId = setTimeout(() => {
        reject(new Error(`ì²˜ë¦¬ ì‹œê°„ ì´ˆê³¼ (${timeout}ms)`));
      }, timeout);

      fn()
        .then(result => {
          clearTimeout(timeoutId);
          resolve(result);
        })
        .catch(error => {
          clearTimeout(timeoutId);
          reject(error);
        });
    });
  }

  delay(ms) {
    return new Promise(resolve => setTimeout(resolve, ms));
  }

  getActiveProcesses() {
    return Array.from(this.activeProcesses.entries()).map(([id, info]) => ({
      processId: id,
      ...info,
      duration: Date.now() - info.startTime
    }));
  }
}

// ========================================
// 5. ì„¸ë§ˆí¬ì–´ í´ë˜ìŠ¤ (ë™ì‹œì„± ì œì–´)
// ========================================

class Semaphore {
  constructor(permits) {
    this.permits = permits;
    this.waitQueue = [];
  }

  async acquire() {
    return new Promise((resolve) => {
      if (this.permits > 0) {
        this.permits--;
        resolve();
      } else {
        this.waitQueue.push(resolve);
      }
    });
  }

  release() {
    if (this.waitQueue.length > 0) {
      const next = this.waitQueue.shift();
      next();
    } else {
      this.permits++;
    }
  }
}

// ========================================
// 6. ê²¬ì ì„œ ì¬ì¡°ë¦½ê¸°
// ========================================

class QuoteReassembler {
  static reassembleQuote(chunkResults, metadata) {
    console.log('ğŸ”§ ê²¬ì ì„œ ì²­í¬ ì¬ì¡°ë¦½ ì‹œì‘:', metadata);
    
    if (chunkResults.length === 1) {
      const { chunkIndex, totalChunks, ...quoteData } = chunkResults[0].result;
      return quoteData;
    }

    // ì²­í¬ ê²°ê³¼ ì •ë ¬
    const sortedResults = chunkResults.sort((a, b) => a.index - b.index);
    
    // ê¸°ë³¸ ê²¬ì ì„œ ë°ì´í„° (ì²« ë²ˆì§¸ ì²­í¬ì—ì„œ)
    const baseQuote = { ...sortedResults[0].result };
    delete baseQuote.chunkIndex;
    delete baseQuote.totalChunks;
    
    // ê·¸ë£¹ë“¤ì„ ë³‘í•©
    const mergedGroups = new Map();
    
    sortedResults.forEach(({ result }) => {
      if (result.groups) {
        result.groups.forEach(group => {
          if (mergedGroups.has(group.id)) {
            // ê¸°ì¡´ ê·¸ë£¹ì— ì•„ì´í…œ ë³‘í•©
            const existingGroup = mergedGroups.get(group.id);
            existingGroup.items = this.mergeItems(existingGroup.items, group.items);
          } else {
            // ìƒˆ ê·¸ë£¹ ì¶”ê°€
            mergedGroups.set(group.id, { ...group });
          }
        });
      }
    });
    
    baseQuote.groups = Array.from(mergedGroups.values());
    
    // ì¬ì¡°ë¦½ ê²€ì¦
    this.validateReassembly(baseQuote, metadata);
    
    console.log('âœ… ê²¬ì ì„œ ì¬ì¡°ë¦½ ì™„ë£Œ');
    return baseQuote;
  }

  static mergeItems(existingItems = [], newItems = []) {
    const itemMap = new Map();
    
    // ê¸°ì¡´ ì•„ì´í…œë“¤ ì¶”ê°€
    existingItems.forEach(item => {
      itemMap.set(item.id, item);
    });
    
    // ìƒˆ ì•„ì´í…œë“¤ ë³‘í•©
    newItems.forEach(item => {
      if (itemMap.has(item.id)) {
        // ê¸°ì¡´ ì•„ì´í…œì˜ ì„¸ë¶€ì‚¬í•­ ë³‘í•©
        const existingItem = itemMap.get(item.id);
        existingItem.details = this.mergeDetails(existingItem.details, item.details);
      } else {
        itemMap.set(item.id, item);
      }
    });
    
    return Array.from(itemMap.values());
  }

  static mergeDetails(existingDetails = [], newDetails = []) {
    const detailMap = new Map();
    
    existingDetails.forEach(detail => {
      detailMap.set(detail.id, detail);
    });
    
    newDetails.forEach(detail => {
      detailMap.set(detail.id, detail);
    });
    
    return Array.from(detailMap.values());
  }

  static validateReassembly(reassembledQuote, originalMetadata) {
    const newAnalysis = QuoteAnalyzer.analyzeQuoteSize(reassembledQuote);
    
    console.log('ğŸ” ì¬ì¡°ë¦½ ê²€ì¦:', {
      ì›ë³¸í¬ê¸°: originalMetadata.analysis.jsonSize,
      ì¬ì¡°ë¦½í¬ê¸°: newAnalysis.jsonSize,
      ì›ë³¸ê·¸ë£¹ìˆ˜: originalMetadata.analysis.totalGroups,
      ì¬ì¡°ë¦½ê·¸ë£¹ìˆ˜: newAnalysis.totalGroups,
      ì›ë³¸ì•„ì´í…œìˆ˜: originalMetadata.analysis.totalItems,
      ì¬ì¡°ë¦½ì•„ì´í…œìˆ˜: newAnalysis.totalItems,
      ì›ë³¸ì„¸ë¶€ì‚¬í•­ìˆ˜: originalMetadata.analysis.totalDetails,
      ì¬ì¡°ë¦½ì„¸ë¶€ì‚¬í•­ìˆ˜: newAnalysis.totalDetails
    });
    
    // ê¸°ë³¸ ê²€ì¦
    const tolerance = 0.05; // 5% í—ˆìš© ì˜¤ì°¨
    if (Math.abs(newAnalysis.totalDetails - originalMetadata.analysis.totalDetails) > originalMetadata.analysis.totalDetails * tolerance) {
      console.warn('âš ï¸ ì¬ì¡°ë¦½ëœ ê²¬ì ì„œì˜ ì„¸ë¶€ì‚¬í•­ ìˆ˜ê°€ ì›ë³¸ê³¼ ë‹¤ë¦…ë‹ˆë‹¤.');
    }
  }
}

// ========================================
// 7. React Hook í†µí•©
// ========================================

export const useLargeQuoteHandler = () => {
  const processingManagerRef = useRef(new ParallelProcessingManager());
  const [isProcessing, setIsProcessing] = useState(false);
  const [processingProgress, setProcessingProgress] = useState(null);

  const handleLargeQuote = useCallback(async (quoteData, processor, options = {}) => {
    setIsProcessing(true);
    setProcessingProgress({ completed: 0, total: 0, stage: 'analyzing' });

    try {
      // 1. í¬ê¸° ë¶„ì„
      const analysis = QuoteAnalyzer.analyzeQuoteSize(quoteData);
      
      if (!analysis.needsChunking) {
        // ì²­í‚¹ì´ í•„ìš”ì—†ëŠ” ê²½ìš°
        setProcessingProgress({ completed: 1, total: 1, stage: 'processing' });
        const result = await processor(quoteData, 0);
        setProcessingProgress({ completed: 1, total: 1, stage: 'complete' });
        return result;
      }

      // 2. ì²­í‚¹
      setProcessingProgress({ completed: 0, total: 0, stage: 'chunking' });
      const { chunks, metadata } = ChunkingEngine.chunkQuote(quoteData);
      
      toast.info(`ğŸ“¦ ëŒ€ìš©ëŸ‰ ê²¬ì ì„œë¥¼ ${chunks.length}ê°œ ì²­í¬ë¡œ ë¶„í• í•˜ì—¬ ì²˜ë¦¬í•©ë‹ˆë‹¤.`, {
        toastId: 'chunking-info'
      });

      // 3. ë³‘ë ¬ ì²˜ë¦¬
      setProcessingProgress({ completed: 0, total: chunks.length, stage: 'processing' });
      
      const processingResult = await processingManagerRef.current.processChunksInParallel(
        chunks,
        processor,
        {
          ...options,
          progressCallback: (progress) => {
            setProcessingProgress({
              ...progress,
              stage: 'processing'
            });
          },
          errorCallback: (error) => {
            toast.error(`ì²­í¬ ${error.chunkIndex} ì²˜ë¦¬ ì‹¤íŒ¨: ${error.error.message}`);
          }
        }
      );

      // 4. ì¬ì¡°ë¦½
      if (processingResult.errors.length > 0) {
        throw new Error(`${processingResult.errors.length}ê°œ ì²­í¬ ì²˜ë¦¬ ì‹¤íŒ¨`);
      }

      setProcessingProgress({ 
        completed: chunks.length, 
        total: chunks.length, 
        stage: 'reassembling' 
      });

      const result = QuoteReassembler.reassembleQuote(processingResult.results, metadata);
      
      setProcessingProgress({ 
        completed: chunks.length, 
        total: chunks.length, 
        stage: 'complete' 
      });

      toast.success(`âœ… ëŒ€ìš©ëŸ‰ ê²¬ì ì„œ ì²˜ë¦¬ ì™„ë£Œ (${chunks.length}ê°œ ì²­í¬)`, {
        toastId: 'chunking-complete'
      });

      return result;

    } catch (error) {
      console.error('ëŒ€ìš©ëŸ‰ ê²¬ì ì„œ ì²˜ë¦¬ ì‹¤íŒ¨:', error);
      toast.error(`âŒ ê²¬ì ì„œ ì²˜ë¦¬ ì‹¤íŒ¨: ${error.message}`);
      throw error;
    } finally {
      setIsProcessing(false);
      setTimeout(() => setProcessingProgress(null), 3000);
    }
  }, []);

  const analyzeQuoteSize = useCallback((quoteData) => {
    return QuoteAnalyzer.analyzeQuoteSize(quoteData);
  }, []);

  return {
    handleLargeQuote,
    analyzeQuoteSize,
    isProcessing,
    processingProgress,
    activeProcesses: processingManagerRef.current.getActiveProcesses()
  };
};

// ========================================
// 8. ë©”ì¸ API ì¸í„°í˜ì´ìŠ¤
// ========================================

export const LargeQuoteManager = {
  // í¬ê¸° ë¶„ì„
  analyze: QuoteAnalyzer.analyzeQuoteSize,
  
  // ì²­í‚¹
  chunk: ChunkingEngine.chunkQuote,
  
  // ë³‘ë ¬ ì²˜ë¦¬
  processInParallel: async (chunks, processor, options) => {
    const manager = new ParallelProcessingManager();
    return manager.processChunksInParallel(chunks, processor, options);
  },
  
  // ì¬ì¡°ë¦½
  reassemble: QuoteReassembler.reassembleQuote,
  
  // í†µí•© ì²˜ë¦¬ í•¨ìˆ˜
  handleLargeQuote: async (quoteData, processor, options = {}) => {
    const analysis = QuoteAnalyzer.analyzeQuoteSize(quoteData);
    
    if (!analysis.needsChunking) {
      return processor(quoteData, 0);
    }

    const { chunks, metadata } = ChunkingEngine.chunkQuote(quoteData);
    const manager = new ParallelProcessingManager();
    const result = await manager.processChunksInParallel(chunks, processor, options);
    
    if (result.errors.length > 0) {
      throw new Error(`${result.errors.length}ê°œ ì²­í¬ ì²˜ë¦¬ ì‹¤íŒ¨`);
    }
    
    return QuoteReassembler.reassembleQuote(result.results, metadata);
  }
};

export default {
  LargeQuoteManager,
  useLargeQuoteHandler,
  QuoteAnalyzer,
  ChunkingEngine,
  ParallelProcessingManager,
  QuoteReassembler,
  CHUNK_CONFIG
};

// ========================================
// 9. ì‚¬ìš© ì˜ˆì‹œ
// ========================================

/*
// React ì»´í¬ë„ŒíŠ¸ì—ì„œ ì‚¬ìš©
const QuoteProcessor = () => {
  const { handleLargeQuote, isProcessing, processingProgress } = useLargeQuoteHandler();

  const saveQuote = async (quoteData) => {
    try {
      const result = await handleLargeQuote(
        quoteData,
        async (chunk, index) => {
          // ê° ì²­í¬ë¥¼ ì„œë²„ì— ì €ì¥
          const response = await fetch('/api/quotes/save-chunk', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({ chunk, chunkIndex: index })
          });
          return response.json();
        },
        {
          maxRetries: 3,
          retryDelay: 1000
        }
      );
      
      console.log('ê²¬ì ì„œ ì €ì¥ ì™„ë£Œ:', result);
    } catch (error) {
      console.error('ê²¬ì ì„œ ì €ì¥ ì‹¤íŒ¨:', error);
    }
  };

  return (
    <div>
      {isProcessing && processingProgress && (
        <div>
          <p>ì²˜ë¦¬ ë‹¨ê³„: {processingProgress.stage}</p>
          <p>ì§„í–‰ë¥ : {processingProgress.completed}/{processingProgress.total}</p>
        </div>
      )}
      <button onClick={() => saveQuote(largeQuoteData)} disabled={isProcessing}>
        ëŒ€ìš©ëŸ‰ ê²¬ì ì„œ ì €ì¥
      </button>
    </div>
  );
};

// ì§ì ‘ API ì‚¬ìš©
const directUsage = async () => {
  const analysis = LargeQuoteManager.analyze(quoteData);
  console.log('ê²¬ì ì„œ ë¶„ì„:', analysis);

  if (analysis.needsChunking) {
    const result = await LargeQuoteManager.handleLargeQuote(
      quoteData,
      async (chunk) => {
        return await saveChunkToServer(chunk);
      }
    );
    console.log('ì²˜ë¦¬ ê²°ê³¼:', result);
  }
};
*/